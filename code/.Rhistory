files_tbmodel = list.files('../../data/',
full.names = T,
pattern = ".RData")
files_tbmodel[1]
dat = get(load(files_tbmodel[1]))
head(dat)
hmlook_back = 6
range_lback = paste0("prev_",seq(hmlook_back,6), collapse = "|")
#para ordenar os dados por data e hora
dat = dat %>% select(c(data,hora,medicao, concat_coord, cenario, range_datas),
c(target),
c(x,y,z),
matches(range_lback)) #mantenho as colunas que contem look_back
library(tidyverse)
range_lback = paste0("prev_",seq(hmlook_back,6), collapse = "|")
#para ordenar os dados por data e hora
dat = dat %>% select(c(data,hora,medicao, concat_coord, cenario, range_datas),
c(target),
c(x,y,z),
matches(range_lback)) #mantenho as colunas que contem look_back
target = "ur"
range_lback = paste0("prev_",seq(hmlook_back,6), collapse = "|")
#para ordenar os dados por data e hora
dat = dat %>% select(c(data,hora,medicao, concat_coord, cenario, range_datas),
c(target),
c(x,y,z),
matches(range_lback)) #mantenho as colunas que contem look_back
head(dat)
setwd("C:/Users/vinic/Google Drive/Mestrado/pratical_project/variability_part2/greenhouse_tseries/code")
#collectiong data to be modeled
files_tbmodel = list.files('../../data/',
full.names = T,
pattern = ".RData")
target = c("ur","temp")
hmlook_back = seq(1:6)
file = files_tbmodel[1]
dat = get(load(file))
library(tidyverse)
library(gtools) #for ordering names
library(reticulate)
rm(list = ls())
gc()
# Saving files into pickle format -----------------------------------------
py_save_object <- function(object, filename, pickle = "pickle") {
builtins <- import_builtins()
pickle <- import(pickle)
handle <- builtins$open(filename, "wb")
on.exit(handle$close(), add = TRUE)
pickle$dump(object, handle, protocol = pickle$HIGHEST_PROTOCOL)
}
#Verifying all files to be modified
files_tbmod = list.files('../../data_raw/',
full.names = T)
# Reading_data ------------------------------------------------------------
#reading and storing all files from files_tbmod
#cleaning columns and creatig concat coordinates for future filtering
df_list = lapply(files_tbmod,
function(x) read_delim(x, delim = ",",col_names = TRUE,trim_ws = T) %>%
select(-X1) %>%
select(-(Lateral_plastico:Meio_poroso)) %>%
mutate(concat_coord = paste0(as.character(x),as.character(y),as.character(z))) %>%
as.data.frame())
# creating look back for time series prediction
look_back = function(df, colNames, lags = 1:6){ #data until one hour back
n = nrow(df)
vet_names = colNames
for(lag in lags){
for(col in vet_names){
new_col = paste0(col,"_prev_",lag)
row_range_in = 1:(n-lag)
df[,new_col] = c(rep(NA,lag), unname(df[row_range_in,col]))
}
}
return(df)
}
#Function to apply look back
apply_lback = function(df){
#criando campo concatenado para filtro
unique_coords = unique(df$concat_coord)
dfi = list()
#defining columns to be lagged
col_lagged = df %>%
select(-c(data,hora,medicao, x, y, z, cenario, concat_coord, range_datas)) %>%
colnames()
# for filtering and lagging for each coordinate (on columns previously selected)
for(xyz in unique_coords){
dfi[[xyz]] = df %>% filter(concat_coord == xyz)
dfi[[xyz]] = look_back(dfi[[xyz]], col_lagged)
}
df = do.call(bind_rows, dfi)
#ordenar as colunas de forma mais interpretavel
sortedNames = mixedsort(colnames(df))
df = df[c(sortedNames)]
#para nao perder o formato das horas no pickle file
df_topickle = df %>% mutate(hora = as.character(hora))
save(df, file = paste0("../../data/df",min(df$data),".RData"))
py_save_object(df_topickle, paste0("../../data/df",min(df_topickle$data),".pickle"),
pickle = "pickle")
return(df)
}
a = lapply(df_list, function(x) apply_lback(x))
files_tbmodel = list.files('../../data/',
full.names = T,
pattern = ".RData")
files_tbmod[[1]]
files_tbmod[1]
path = files_tbmod[1]
dat = get(load(file))
file = files_tbmod[1]
dat = get(load(file))
files_tbmodel = list.files('../../data/',
full.names = T,
pattern = ".RData")
files_tbmodel
file = files_tbmodel[1]
dat = get(load(file))
target = "TEMP"
target = "temp"
hmlook_back = 1
hmlook_back = 6
range_lback = paste0("prev_",seq(hmlook_back,6), collapse = "|")
range_lback
dat = dat %>% select(c(data,hora,medicao, concat_coord, cenario, range_datas),
c(target),
c(x,y,z),
matches(range_lback)) #mantenho as colunas que contem look_back
head(dat)
cenario = unique(dat$cenario)
# mantaining only complete caes (in function of variable look back (done))
dat = dat[complete.cases(dat),] %>% arrange(data,hora)
head(dat)
dat = dat %>% select(-c(data,hora,medicao, concat_coord, cenario, range_datas))
dat = dat %>% mutate_at(vars("x","y","z"), funs(as.factor))
head(dat)
library(mlr)
?makeDummyFeaturesWrapper
unique(dat$dir_vent_1_prev_6)
unique(dat$dir_vent_2_prev_6)
unique(dat$vel_vent_2_prev_6)
unique(dat$vel_vento_2_prev_6)
dat = get(load(file))
#definindo o range de look_back
range_lback = paste0("prev_",seq(hmlook_back,6), collapse = "|")
#para ordenar os dados por data e hora
dat = dat %>% select(c(data,hora,medicao, concat_coord, cenario, range_datas),
c(target),
c(x,y,z),
matches(range_lback)) #mantenho as colunas que contem look_back
#criando variaveis para compor o arquivo de resultados
cenario = unique(dat$cenario)
# mantaining only complete caes (in function of variable look back (done))
dat = dat[complete.cases(dat),] %>% arrange(data,hora)
#train_lines are those considering the 7 first dates. Test is all the three remaining days
train_lines = which(dat$data %in% unique(dat$data)[1:7]) #sete primeiras datas
test_lines = which(dat$data %in% unique(dat$data)[8:10])
#infos for results saving
hora = dat[test_lines,]$hora
data = dat[test_lines,]$data
range_datas = unique(dat$range_datas)
concat_coord = dat[test_lines,]$data
#creating blocking column for CV - train_lines(1:5) and test_lines(6)
blocking_train = rep(1:5, each = ceiling(length(train_lines)/5))
blocking_train = blocking_train[1:length(train_lines)]
blocking_test = rep(6, length(test_lines))
block = as.factor(c(blocking_train,blocking_test))
#Tirando as colunas que afetarao a modelagem. Ou possuem correlacao ou nao fazem parte do set up
dat = dat %>% select(-c(data,hora,medicao, concat_coord, cenario, range_datas))
dat = dat %>% mutate_at(vars("x","y","z"), funs(as.factor))
regr_task = makeRegrTask(id = 'svm', data = dat, target = target, blocking = block)
# especifica seed para particionar o conjunto de dados
set.seed(1)
rval = makeFixedHoldoutInstance(train.inds = train_lines, test.inds = test_lines,
size = nrow(dat))
rmod = makeResampleDesc(method = 'CV', predict='test',
iters = 5)
# especifica que o K deve ser variado de 1 a 20
parameters = makeParamSet(
makeDiscreteParam("cost", values = 2^(-2:2)),
makeDiscreteParam("gamma", values = 2^(-2:2)),
makeNumericParam("epsilon",lower = 0.05, upper = 0.3)
)
# especifica que usaremos uma busca aleatoria
ctrl = makeTuneControlRandom(maxit = 1L)
#parallelStart(mode = 'multicore', cpus = 12, level = 'mlr.tuneParams')
# cria um learner de regressao com svm, que faz o preprocessing de criar variaveis dummy
base_learner = makeDummyFeaturesWrapper("regr.svm")
# considera agora que o learner vai ser o melhor resultado de um procedimento de tunning com CV
lrn = makeTuneWrapper(base_learner, resampling = rmod, par.set = parameters, control = ctrl,
measures = mae)
# avalia o modelo resultante do tunning com cross-validation (rmod) usando o conjunto de validacao (rval)
r = resample(lrn, regr_task, resampling = rval, extract = getTuneResult, show.info = TRUE,
models=TRUE, measures = mae)
getResamplingIndices(r)
r
getResamplingIndices(lrn)
r = resample(lrn, regr_task, resampling = rval, extract = getTuneResult, show.info = TRUE,
models=TRUE, measures = mae)
getResamplingIndices(lrn)
getResamplingIndices(r)
getResamplingIndices(r)$train.inds
getResamplingIndices(r)$train.inds[[2]]
getResamplingIndices(r)$train.inds[[1]]
getResamplingIndices(r)[[1]]
getResamplingIndices(r)[[2]]
getResamplingIndices(r)[[3]]
getResamplingIndices(r)[[1]][1]
getResamplingIndices(r)[[1]][2]
getResamplingIndices(r)[[1]][3]
getResamplingIndices(rmod)
getResamplingIndices(lrn)
getResamplingIndices(r)
files_tbmodel = list.files('../../data/',
full.names = T,
pattern = ".RData")
file = files_tbmodel[1]
hmlook_back = 6
target = "temp"
dat = get(load(file))
#definindo o range de look_back
range_lback = paste0("prev_",seq(hmlook_back,6), collapse = "|")
#para ordenar os dados por data e hora
dat = dat %>% select(c(data,hora,medicao, concat_coord, cenario, range_datas),
c(target),
c(x,y,z),
matches(range_lback)) #mantenho as colunas que contem look_back
#criando variaveis para compor o arquivo de resultados
cenario = unique(dat$cenario)
# mantaining only complete caes (in function of variable look back (done))
dat = dat[complete.cases(dat),] %>% arrange(data,hora)
#train_lines are those considering the 7 first dates. Test is all the three remaining days
train_lines = which(dat$data %in% unique(dat$data)[1:7]) #sete primeiras datas
test_lines = which(dat$data %in% unique(dat$data)[8:10])
#creating blocking column for CV - train_lines(1:5) and test_lines(6)
blocking_train = rep(1:5, each = ceiling(length(train_lines)/5))
blocking_train = blocking_train[1:length(train_lines)]
blocking_test = rep(6, length(test_lines))
block = as.factor(c(blocking_train,blocking_test))
#Tirando as colunas que afetarao a modelagem. Ou possuem correlacao ou nao fazem parte do set up
dat = dat %>% select(-c(data,hora,medicao, concat_coord, cenario, range_datas))
dat = dat %>% mutate_at(vars("x","y","z"), funs(as.factor))
regr_task = makeRegrTask(id = 'brt', data = dat, target = target, blocking = block)
# especifica seed para particionar o conjunto de dados
set.seed(1)
rval = makeFixedHoldoutInstance(train.inds = train_lines, test.inds = test_lines,
size = nrow(dat))
rmod = makeResampleDesc(method = 'CV', predict='test',
iters = 5)
# especifica que o K deve ser variado de 1 a 20
parameters = makeParamSet(
makeDiscreteParam("n.trees", seq(100,1000, by=100)),
makeDiscreteParam("interaction.depth",seq(1,5,by=1)),
makeNumericParam("shrinkage",lower = 0.001, upper = 0.2)
)
# especifica que usaremos uma busca aleatoria
ctrl = makeTuneControlRandom(maxit = 1L)
#parallelStart(mode = 'multicore', cpus = 12, level = 'mlr.tuneParams')
# cria um learner de regressao com gbm, que faz o preprocessing de criar variaveis dummy
base_learner = makeDummyFeaturesWrapper("regr.gbm")
# considera agora que o learner vai ser o melhor resultado de um procedimento de tunning com CV
lrn = makeTuneWrapper(base_learner, resampling = rmod, par.set = parameters, control = ctrl,
measures = mae)
# avalia o modelo resultante do tunning com cross-validation (rmod) usando o conjunto de validacao (rval)
r = resample(lrn, regr_task, resampling = rval, extract = getTuneResult, show.info = TRUE,
models=TRUE, measures = mae)
warnings()
getResamplingIndices(r)
getResamplingIndices(r)$train.inds$train.inds
getResamplingIndices(r)$train.inds
getResamplingIndices(r$models)
getResamplingIndices(r$task.desc)
getResamplingIndices(r$extract)
getResamplingIndices(r$measures.train)
getResamplingIndices(r$pred)
getResamplingIndices(r)
getResamplingIndices(base_learner)
getResamplingIndices(r)
a = getResamplingIndices(r)
a$train.inds
a$train.inds[[1]]
a$train.inds[[2]]
a$train.inds
?getResamplingIndices
getResamplingIndices(r, inner = TRUE)
a = getResamplingIndices(r, inner = TRUE)
a[[1]]$train.inds
a[[1]]$train.inds[[1]]
sort(a[[1]]$train.inds[[1]])
setwd("C:/Users/vinic/Google Drive/Mestrado/pratical_project/variability_part2/greenhouse_tseries/code")
library(tidyverse)
files_to_viz = list.files("../../results/", pattern = ".txt", recursive = T)
files_to_viz
files_to_viz = list.files("../../results/", pattern = "ypred*.txt", recursive = T)
files_to_viz
files_to_viz = list.files("../../results/", pattern = "ypred", recursive = T)
files_to_viz
read_table(files_to_viz[[1]])
files_to_viz = list.files("../../results/", pattern = "ypred", recursive = T, full.names = T)
read_table(files_to_viz[[1]])
res = read_table(files_to_viz[[1]], sep = "\")
res = read_table(files_to_viz[[1]], sep = "|")
?read_table
res = read_table(files_to_viz[[1]],col_names = FALSE, skip = 1)
head(RES)
head(res)
?read.table
res = read.table(files_to_viz[[1]],header = FALSE, sep = " ", skip = 1)
head(res)
res = read.table(files_to_viz[[50]],header = FALSE, sep = " ", skip = 1)
head(res)
res = read.table(files_to_viz[[50]],header = FALSE, sep = " ", skip = 0)
head(res)
res = read.table(files_to_viz[[50]],header = T, sep = " ", skip = 0)
head(res)
# getting BRT results in same format
files_to_c = list.files("../../results/brt", pattern = "ypred", recursive = T, full.names = T)
res = read.table(files_to_viz[[51]],header = T, sep = " ", skip = 0)
head(res)
res = read.table(files_to_viz[[1]],header = T, sep = " ", skip = 0)
head(res)
res = read.table(files_to_viz[[50]],header = T, sep = " ", skip = 0)
head(res)
res1 = read.table(files_to_viz[[50]],header = T, sep = " ", skip = 0)
head(res1)
range_cen1 = res1$range_datas
data_cen1 = res1$data
hora_cen1 = res1$hora
files_to_c = list.files("../../results/brt", pattern = "ypred", recursive = T, full.names = T)
for(i in 1:length(files_to_c)){
res = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0)
res  = res %>% mutate(tecnica = "brt") %>% rename(yobs = truth, ypred = response)
if(res$cenario == "Cenario_1"){
res = res %>% mutate(range_datas = range_cen1, data = data_cen1, hora = hora_cen1)
}
}
warnings()
head(res)
i = 1
res = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0)
head(res)
range_cen1
files_to_c = list.files("../../results/brt", pattern = "ypred", recursive = T, full.names = T)
for(i in 1:length(files_to_c)){
res = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0)
res  = res %>% mutate(tecnica = "brt") %>% rename(yobs = truth, ypred = response)
if(unique(res$cenario) == "Cenario_1"){
res = res %>% mutate(range_datas = range_cen1, data = data_cen1, hora = hora_cen1)
}
}
i = 1
res = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0)
head(res)
i = 1
i = 2
res = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0)
head(res)
unique(res$cenario) == "Cenario_1"
res = res %>% mutate(range_datas = range_cen1, data = data_cen1, hora = hora_cen1)
head(res)
i = 1
res = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0)
res  = res %>% mutate(tecnica = "brt") %>% rename(yobs = truth, ypred = response)
if(unique(res$cenario) == "Cenario_1"){
res = res %>% mutate(range_datas = range_cen1, data = data_cen1, hora = hora_cen1)
}
head(res)
head(res1)
res = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0)
res  = res %>% mutate(tecnica = "brt") %>% rename(yobs = truth, ypred = response)
res = res %>% select(-c(iter,set))
if(unique(res$cenario) == "Cenario_1"){
res = res %>% mutate(range_datas = range_cen1, data = data_cen1, hora = hora_cen1)
}
head(res)
res = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0)
res  = res %>% mutate(tecnica = "brt") %>% rename(yobs = truth, ypred = response)
res = res %>% select(-c(iter,set,id))
if(unique(res$cenario) == "Cenario_1"){
res = res %>% mutate(range_datas = range_cen1, data = data_cen1, hora = hora_cen1)
}
head(res)
head(res1)
concat_cen1 = res1$concat_coord
res = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0)
res  = res %>% mutate(tecnica = "brt") %>% rename(yobs = truth, ypred = response)
res = res %>% select(-c(iter,set,id))
if(unique(res$cenario) == "Cenario_1"){
res = res %>% mutate(range_datas = range_cen1, data = data_cen1, hora = hora_cen1,
concat_coord = concat_cen1)
}
length(colnames(res))
length(colnames(res1))
files_to_viz[[i]]
files_to_c = list.files("../../results/brt", pattern = "ypred", recursive = T, full.names = T)
for(i in 1:length(files_to_c)){
res = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0)
if(unique(res$cenario) == "Cenario_1"){
res  = res %>% mutate(tecnica = "brt") %>% rename(yobs = truth, ypred = response)
res = res %>% select(-c(iter,set,id))
res = res %>% mutate(range_datas = range_cen1, data = data_cen1, hora = hora_cen1,
concat_coord = concat_cen1)
res = res[,c("tecnica","cenario","range_datas","concat_coord","data",
"hora","target","hmlook_back","yobs","ypred")]
write.table(res, file = files_to_viz[[i]] )
}
}
files_to_viz = list.files("../../results/", pattern = "ypred", recursive = T, full.names = T)
res1 = read.table(files_to_viz[[1]],header = T, sep = " ", skip = 0)
head(res1)
res1 = read.table(files_to_viz[[50]],header = T, sep = " ", skip = 0)
head(res1)
res1 = read.table(files_to_viz[[51]],header = T, sep = " ", skip = 0)
head(res1)
res1 = read.table(files_to_viz[[51]],header = T, sep = " ", skip = 0)
range_cen5 = res1$range_datas
data_cen5 = res1$data
hora_cen5 = res1$hora
concat_cen5 = res1$concat_coord
head9res1
head(res1)
files_to_c = list.files("../../results/brt", pattern = "ypred", recursive = T, full.names = T)
for(i in 1:length(files_to_c)){
res = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0)
if(unique(res$cenario) == "Cenario_5"){
res  = res %>% mutate(tecnica = "brt") %>% rename(yobs = truth, ypred = response)
res = res %>% select(-c(iter,set,id))
res = res %>% mutate(range_datas = range_cen5, data = data_cen5, hora = hora_cen5,
concat_coord = concat_cen5)
res = res[,c("tecnica","cenario","range_datas","concat_coord","data",
"hora","target","hmlook_back","yobs","ypred")]
write.table(res, file = files_to_viz[[i]] )
}
}
res1 = read.table(files_to_viz[[52]],header = T, sep = " ", skip = 0)
head(res1)
res1 = read.table(files_to_viz[[53]],header = T, sep = " ", skip = 0)
head(res1)
res1 = read.table(files_to_viz[[53]],header = T, sep = " ", skip = 0)
range_cen7 = res1$range_datas
data_cen7 = res1$data
hora_cen7 = res1$hora
concat_cen7 = res1$concat_coord
for(i in 1:length(files_to_c)){
res = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0)
if(unique(res$cenario) == "Cenario_7"){
res  = res %>% mutate(tecnica = "brt") %>% rename(yobs = truth, ypred = response)
res = res %>% select(-c(iter,set,id))
res = res %>% mutate(range_datas = range_cen7, data = data_cen7, hora = hora_cen7,
concat_coord = concat_cen7)
res = res[,c("tecnica","cenario","range_datas","concat_coord","data",
"hora","target","hmlook_back","yobs","ypred")]
write.table(res, file = files_to_viz[[i]] )
}
}
res1 = read.table(files_to_viz[[54]],header = T, sep = " ", skip = 0)
head(res1)
res1 = read.table(files_to_viz[[54]],header = T, sep = " ", skip = 0)
range_cen9 = res1$range_datas
data_cen9 = res1$data
hora_cen9 = res1$hora
concat_cen9 = res1$concat_coord
files_to_c = list.files("../../results/brt", pattern = "ypred", recursive = T, full.names = T)
for(i in 1:length(files_to_c)){
res = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0)
if(unique(res$cenario) == "Cenario_9"){
res  = res %>% mutate(tecnica = "brt") %>% rename(yobs = truth, ypred = response)
res = res %>% select(-c(iter,set,id))
res = res %>% mutate(range_datas = range_cen9, data = data_cen9, hora = hora_cen9,
concat_coord = concat_cen9)
res = res[,c("tecnica","cenario","range_datas","concat_coord","data",
"hora","target","hmlook_back","yobs","ypred")]
write.table(res, file = files_to_viz[[i]] )
}
}
files_to_viz = list.files("../../results/", pattern = "ypred", recursive = T, full.names = T)
res =list()
for(i in 1:length(files_to_viz)){
res[[i]] = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0)
}
results = do.call(res,bind_rows)
results = do.call(bind_rows, res)
warnings()
res[[1]]
str(res[[1]])
files_to_viz = list.files("../../results/", pattern = "ypred", recursive = T, full.names = T)
res =list()
for(i in 1:length(files_to_viz)){
res[[i]] = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0) %>%
mutate_if(is.factor, as.character)
}
results = do.call(bind_rows, res)
head(results)
dim(results)
files_to_viz = list.files("../../results/", pattern = "ypred", recursive = T, full.names = T)
res =list()
for(i in 1:length(files_to_viz)){
res[[i]] = read.table(files_to_viz[[i]],header = T, sep = " ", skip = 0) %>%
mutate_if(is.factor, as.character)
}
results = do.call(bind_rows, res) %>% mutate(erro = ypred - yobs)
head(results)
# Plotting MAE progress over Scenarios -----------------------------------
res1 = results %>% group_by(tecnica,target,cenario, hmlook_back) %>% summarise(mae = mean(abs(erro)))
head(res)
head(res1)
dim(res1)
res1 %>% filter(target == "temp") %>%
ggplot(aes(x = hmlook_back, y = mae, col = cenario)) %>% geom_line()
res1 %>% filter(target == "temp") %>%
ggplot(aes(x = hmlook_back, y = mae, col = cenario)) + geom_line()
res1 = results %>% group_by(tecnica,target,cenario, hmlook_back) %>% summarise(mae = mean(abs(erro)))
res1 %>% filter(target == "temp") %>%
ggplot(aes(x = hmlook_back, y = mae, col = cenario)) + geom_line()
